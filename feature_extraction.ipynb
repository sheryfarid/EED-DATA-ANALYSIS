{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction of normal (also same for stroke)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import kurtosis, skew\n",
    "import pywt  # For wavelet features\n",
    "\n",
    "# New channel groups and features per the mapping\n",
    "channels_features_map = {\n",
    "    \"FP1\": [\"mean\", \"var\", \"hjorth\", \"approx_entropy\", \"alpha_beta_ratio\"],\n",
    "    \"FP2\": [\"mean\", \"var\", \"hjorth\", \"approx_entropy\", \"alpha_beta_ratio\"],\n",
    "\n",
    "    \"FC3\": [\"line_length\", \"ssc\", \"zcr\", \"alpha_beta_power\", \"wavelet_energy\", \"entropy\"],\n",
    "    \"FC4\": [\"line_length\", \"ssc\", \"zcr\", \"alpha_beta_power\", \"wavelet_energy\", \"entropy\"],\n",
    "    \"FCZ\": [\"line_length\", \"ssc\", \"zcr\", \"alpha_beta_power\", \"wavelet_energy\", \"entropy\"],\n",
    "\n",
    "    \"F3\": [\"var\", \"rms\", \"ptp\", \"theta_beta_ratio\", \"spectral_entropy\"],\n",
    "    \"F4\": [\"var\", \"rms\", \"ptp\", \"theta_beta_ratio\", \"spectral_entropy\"],\n",
    "    \"FZ\": [\"var\", \"rms\", \"ptp\", \"theta_beta_ratio\", \"spectral_entropy\"],\n",
    "\n",
    "    \"C3\": [\"hjorth\", \"psd_delta_theta\", \"line_length\", \"delta_theta_ratio\"],\n",
    "    \"C4\": [\"hjorth\", \"psd_delta_theta\", \"line_length\", \"delta_theta_ratio\"],\n",
    "    \"CZ\": [\"hjorth\", \"psd_delta_theta\", \"line_length\", \"delta_theta_ratio\"],\n",
    "\n",
    "    \"CP3\": [\"sample_entropy\", \"ptp\", \"delta_theta_ratio\", \"wavelet_coefficients\", \"entropy\"],\n",
    "    \"CP4\": [\"sample_entropy\", \"ptp\", \"delta_theta_ratio\", \"wavelet_coefficients\", \"entropy\"],\n",
    "    \"CPZ\": [\"sample_entropy\", \"ptp\", \"delta_theta_ratio\", \"wavelet_coefficients\", \"entropy\"],\n",
    "}\n",
    "\n",
    "BANDS = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30)\n",
    "}\n",
    "\n",
    "fs = 160  # Sampling frequency (Hz)\n",
    "\n",
    "\n",
    "def compute_bandpower(signal, fs, band):\n",
    "    fmin, fmax = band\n",
    "    freqs, psd = welch(signal, fs=fs, nperseg=fs*2)\n",
    "    mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "    power = np.trapz(psd[mask], freqs[mask])\n",
    "    return power\n",
    "\n",
    "\n",
    "def line_length(signal):\n",
    "    return np.sum(np.abs(np.diff(signal)))\n",
    "\n",
    "\n",
    "def slope_sign_changes(signal):\n",
    "    diff_signal = np.diff(signal)\n",
    "    diff_sign = np.sign(diff_signal)\n",
    "    ssc = np.sum(diff_sign[:-1] != diff_sign[1:])\n",
    "    return ssc\n",
    "\n",
    "\n",
    "def zero_crossing_rate(signal):\n",
    "    return np.sum((signal[:-1] * signal[1:]) < 0)\n",
    "\n",
    "\n",
    "def peak_to_peak(signal):\n",
    "    return np.ptp(signal)\n",
    "\n",
    "\n",
    "def spectral_entropy(signal):\n",
    "    freqs, psd = welch(signal, fs=fs, nperseg=fs*2)\n",
    "    psd_norm = psd / np.sum(psd)\n",
    "    psd_norm = psd_norm[psd_norm > 0]  # Avoid log(0)\n",
    "    entropy = -np.sum(psd_norm * np.log2(psd_norm))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def approximate_entropy(signal, m=2, r=None):\n",
    "    # Approximate entropy calculation simplified version\n",
    "    N = len(signal)\n",
    "    if r is None:\n",
    "        r = 0.2 * np.std(signal)\n",
    "    def _phi(m):\n",
    "        x = np.array([signal[i:i + m] for i in range(N - m + 1)])\n",
    "        C = np.sum(np.max(np.abs(x[:, None] - x[None, :]), axis=2) <= r, axis=0) / (N - m + 1)\n",
    "        return np.sum(np.log(C)) / (N - m + 1)\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "\n",
    "def sample_entropy(signal, m=2, r=None):\n",
    "    # Sample entropy approximation\n",
    "    N = len(signal)\n",
    "    if r is None:\n",
    "        r = 0.2 * np.std(signal)\n",
    "\n",
    "    def _count_similar(seg_len):\n",
    "        x = np.array([signal[i:i + seg_len] for i in range(N - seg_len + 1)])\n",
    "        count = 0\n",
    "        total = 0\n",
    "        for i in range(len(x)):\n",
    "            dist = np.max(np.abs(x - x[i]), axis=1)\n",
    "            count += np.sum(dist <= r) - 1\n",
    "            total += len(dist) - 1\n",
    "        return count / total if total > 0 else 0\n",
    "\n",
    "    B = _count_similar(m)\n",
    "    A = _count_similar(m + 1)\n",
    "    if B == 0:\n",
    "        return np.inf\n",
    "    if A == 0:\n",
    "        return -np.log(1.0 / (N - m))\n",
    "    return -np.log(A / B)\n",
    "\n",
    "\n",
    "def wavelet_energy(signal, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    energy = np.sum([np.sum(c ** 2) for c in coeffs])\n",
    "    return energy\n",
    "\n",
    "\n",
    "def wavelet_coefficients_stats(signal, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    stats = {}\n",
    "    for i, c in enumerate(coeffs):\n",
    "        stats[f\"wavelet_coeff_mean_level_{i}\"] = np.mean(c)\n",
    "        stats[f\"wavelet_coeff_std_level_{i}\"] = np.std(c)\n",
    "    return stats\n",
    "\n",
    "\n",
    "def hjorth_parameters(signal):\n",
    "    diff_signal = np.diff(signal)\n",
    "    diff_diff_signal = np.diff(diff_signal)\n",
    "    activity = np.var(signal)\n",
    "    mobility = np.sqrt(np.var(diff_signal) / activity) if activity != 0 else 0\n",
    "    complexity = np.sqrt(np.var(diff_diff_signal) / np.var(diff_signal)) if np.var(diff_signal) != 0 else 0\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "\n",
    "def extract_features_from_trial(trial_df):\n",
    "    features = {}\n",
    "    for ch, feats in channels_features_map.items():\n",
    "        if ch not in trial_df.columns:\n",
    "            continue\n",
    "        signal = trial_df[ch].values\n",
    "        \n",
    "        # Precompute band power for some features\n",
    "        bandpowers = {band: compute_bandpower(signal, fs, band_range) for band, band_range in BANDS.items()}\n",
    "\n",
    "        # Helper ratios\n",
    "        alpha_beta_ratio = bandpowers[\"alpha\"] / bandpowers[\"beta\"] if bandpowers[\"beta\"] != 0 else 0\n",
    "        theta_beta_ratio = bandpowers[\"theta\"] / bandpowers[\"beta\"] if bandpowers[\"beta\"] != 0 else 0\n",
    "        delta_theta_ratio = bandpowers[\"delta\"] / bandpowers[\"theta\"] if bandpowers[\"theta\"] != 0 else 0\n",
    "\n",
    "        for feat in feats:\n",
    "            if feat == \"mean\":\n",
    "                features[f\"{ch}_mean\"] = np.mean(signal)\n",
    "            elif feat == \"var\":\n",
    "                features[f\"{ch}_var\"] = np.var(signal)\n",
    "            elif feat == \"rms\":\n",
    "                features[f\"{ch}_rms\"] = np.sqrt(np.mean(signal ** 2))\n",
    "            elif feat == \"skew\":\n",
    "                features[f\"{ch}_skew\"] = skew(signal)\n",
    "            elif feat == \"kurtosis\":\n",
    "                features[f\"{ch}_kurtosis\"] = kurtosis(signal)\n",
    "            elif feat == \"approx_entropy\":\n",
    "                features[f\"{ch}_approx_entropy\"] = approximate_entropy(signal)\n",
    "            elif feat == \"sample_entropy\":\n",
    "                features[f\"{ch}_sample_entropy\"] = sample_entropy(signal)\n",
    "            elif feat == \"line_length\":\n",
    "                features[f\"{ch}_line_length\"] = line_length(signal)\n",
    "            elif feat == \"ssc\":\n",
    "                features[f\"{ch}_ssc\"] = slope_sign_changes(signal)\n",
    "            elif feat == \"zcr\":\n",
    "                features[f\"{ch}_zero_crossings\"] = zero_crossing_rate(signal)\n",
    "            elif feat == \"peak_to_peak\" or feat == \"ptp\":\n",
    "                features[f\"{ch}_peak_to_peak\"] = peak_to_peak(signal)\n",
    "            elif feat == \"hjorth\":\n",
    "                activity, mobility, complexity = hjorth_parameters(signal)\n",
    "                features[f\"{ch}_hjorth_activity\"] = activity\n",
    "                features[f\"{ch}_hjorth_mobility\"] = mobility\n",
    "                features[f\"{ch}_hjorth_complexity\"] = complexity\n",
    "            elif feat == \"alpha_beta_ratio\":\n",
    "                features[f\"{ch}_alpha_beta_ratio\"] = alpha_beta_ratio\n",
    "            elif feat == \"theta_beta_ratio\":\n",
    "                features[f\"{ch}_theta_beta_ratio\"] = theta_beta_ratio\n",
    "            elif feat == \"delta_theta_ratio\":\n",
    "                features[f\"{ch}_delta_theta_ratio\"] = delta_theta_ratio\n",
    "            elif feat == \"alpha_beta_power\":\n",
    "                features[f\"{ch}_alpha_power\"] = bandpowers[\"alpha\"]\n",
    "                features[f\"{ch}_beta_power\"] = bandpowers[\"beta\"]\n",
    "                features[f\"{ch}_alpha_beta_ratio\"] = alpha_beta_ratio\n",
    "            elif feat == \"psd_delta_theta\":\n",
    "                features[f\"{ch}_delta_power\"] = bandpowers[\"delta\"]\n",
    "                features[f\"{ch}_theta_power\"] = bandpowers[\"theta\"]\n",
    "                features[f\"{ch}_delta_theta_ratio\"] = delta_theta_ratio\n",
    "            elif feat == \"spectral_entropy\":\n",
    "                features[f\"{ch}_spectral_entropy\"] = spectral_entropy(signal)\n",
    "            elif feat == \"entropy\":\n",
    "                # compute histogram entropy as previously (approximate)\n",
    "                probs, _ = np.histogram(signal, bins=30, density=True)\n",
    "                probs = probs[probs > 0]\n",
    "                entropy_val = -np.sum(probs * np.log2(probs))\n",
    "                features[f\"{ch}_entropy\"] = entropy_val\n",
    "            elif feat == \"wavelet_energy\":\n",
    "                features[f\"{ch}_wavelet_energy\"] = wavelet_energy(signal)\n",
    "            elif feat == \"wavelet_coefficients\":\n",
    "                wavelet_stats = wavelet_coefficients_stats(signal)\n",
    "                for key, val in wavelet_stats.items():\n",
    "                    features[f\"{ch}_{key}\"] = val\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_root = Path(r\"D:\\ai\\eeg_data\\nromal\\preprocessed_trials\\normal\")\n",
    "output_root = Path(r\"D:\\ai\\eeg_data\\nromal\\normal_feature\")\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "normal_subjects = [f\"S{i:03}\" for i in range(1, 110)]  # S001 to S109\n",
    "\n",
    "for subj in normal_subjects:\n",
    "    print(f\" Extracting features for NORMAL: {subj}\")\n",
    "    subj_folder = input_root / subj\n",
    "    output_file = output_root / f\"{subj}_features.csv\"\n",
    "\n",
    "    all_features = []\n",
    "\n",
    "    if not subj_folder.exists():\n",
    "        print(f\" Missing subject folder: {subj_folder}\")\n",
    "        continue\n",
    "\n",
    "    for trial_file in subj_folder.glob(\"trial_*.csv\"):\n",
    "        trial_df = pd.read_csv(trial_file)\n",
    "\n",
    "        # Basic info\n",
    "        meta = {\n",
    "            \"trial_id\": trial_df[\"trial_id\"].iloc[0],\n",
    "            \"label\": trial_df[\"label\"].iloc[0],\n",
    "            \"onset_sec\": trial_df[\"onset_sec\"].iloc[0],\n",
    "            \"duration_sec\": trial_df[\"duration_sec\"].iloc[0]\n",
    "        }\n",
    "\n",
    "        feat = extract_features_from_trial(trial_df)   # <--- Reuse your existing function here\n",
    "        all_features.append({**meta, **feat})\n",
    "\n",
    "    if all_features:\n",
    "        df_out = pd.DataFrame(all_features)\n",
    "        df_out.to_csv(output_file, index=False)\n",
    "        print(f\" Saved: {output_file}\")\n",
    "    else:\n",
    "        print(f\" No trials found for {subj}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab8358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
